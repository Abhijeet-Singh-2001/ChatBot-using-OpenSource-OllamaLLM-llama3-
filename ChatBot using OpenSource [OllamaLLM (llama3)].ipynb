{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e571acf-720e-4e34-8395-0ce964f0a68b",
   "metadata": {},
   "source": [
    "# ChatBot Using OllamaLLM (llama3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66327e57-d5c3-453d-ab67-cd5e1eeecdec",
   "metadata": {},
   "source": [
    "# # Python and C++ Code Generator Chatbot - Documentation\n",
    "\n",
    "## General Overview\n",
    "This project is a **Python-based chatbot** that generates code solutions for user-provided programming tasks. It uses **LangChain** and **Ollama (LLaMA 3)** to interact with a local large language model (LLM). The system:\n",
    "\n",
    "1. Accepts a **user question or request**.\n",
    "2. Generates a **well-commented, optimized Python and C++ code solution**.\n",
    "3. Outputs the solution in a **JSON format**, which is then extracted and displayed cleanly.\n",
    "\n",
    "The chatbot also includes a **mock fallback LLM**, so it works even if Ollama is not running.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dependencies\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "pip install langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4e6b1c-9da4-4a94-9473-786932782d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\anaconda\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.3.77)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\anaconda\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (0.4.31)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\anaconda\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb119f1-1181-4c79-baec-3d854a38ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\anaconda\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in c:\\users\\anaconda\\lib\\site-packages (from langchain-ollama) (0.6.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-ollama) (0.3.77)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abhijeet singh\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafda74-4ea7-4f52-b542-89ed2d3b88be",
   "metadata": {},
   "source": [
    "# Chatbot Code Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b816906e-5cb8-434f-8a0b-ec5c263cb631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to initialize Ollama with model: llama3...\n",
      "Ollama connection successful.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Python problem (e.g., Write a Python program to calculate the factorial of a given number using a loop.):  Write a Python program to calculate the factorial of a given number using a loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking LLM Chain ---\n",
      "[\n",
      "    {\n",
      "        \"question\": \"Write a Python program to calculate the factorial of a given number using a loop.\",\n",
      "        \"code\": \"\"\"\n",
      "def factorial(n):\n",
      "    # Initialize the result variable\n",
      "    result = 1\n",
      "    \n",
      "    # Loop until n is 0\n",
      "    for i in range(1, n + 1):\n",
      "        # Multiply the result by i\n",
      "        result *= i\n",
      "    \n",
      "    return result\n",
      "\n",
      "# Test the function with a sample input\n",
      "num = int(input(\"Enter a number: \"))\n",
      "print(f\"The factorial of {num} is {factorial(num)}\")\n",
      "\"\"\"\n",
      "    }\n",
      "]\n",
      "[{'question': 'Write a Python program to calculate the factorial of a given number using a loop.', 'code': '\\ndef factorial(n):\\n    # Initialize the result variable\\n    result = 1\\n    \\n    # Loop until n is 0\\n    for i in range(1, n + 1):\\n        # Multiply the result by i\\n        result *= i\\n    \\n    return result\\n\\n# Test the function with a sample input\\nnum = int(input(\"Enter a number: \"))\\nprint(f\"The factorial of {num} is {factorial(num)}\")\\n'}]\n",
      "{'question': 'Write a Python program to calculate the factorial of a given number using a loop.', 'code': '\\ndef factorial(n):\\n    # Initialize the result variable\\n    result = 1\\n    \\n    # Loop until n is 0\\n    for i in range(1, n + 1):\\n        # Multiply the result by i\\n        result *= i\\n    \\n    return result\\n\\n# Test the function with a sample input\\nnum = int(input(\"Enter a number: \"))\\nprint(f\"The factorial of {num} is {factorial(num)}\")\\n'}\n",
      "Write a Python program to calculate the factorial of a given number using a loop.\n",
      "\n",
      "def factorial(n):\n",
      "    # Initialize the result variable\n",
      "    result = 1\n",
      "    \n",
      "    # Loop until n is 0\n",
      "    for i in range(1, n + 1):\n",
      "        # Multiply the result by i\n",
      "        result *= i\n",
      "    \n",
      "    return result\n",
      "\n",
      "# Test the function with a sample input\n",
      "num = int(input(\"Enter a number: \"))\n",
      "print(f\"The factorial of {num} is {factorial(num)}\")\n",
      "\n",
      "\n",
      "--- Extracted Results ---\n",
      "Original Question: Write a Python program to calculate the factorial of a given number using a loop.\n",
      "\n",
      "Generated Python Code:\n",
      "\n",
      "def factorial(n):\n",
      "    # Initialize the result variable\n",
      "    result = 1\n",
      "    \n",
      "    # Loop until n is 0\n",
      "    for i in range(1, n + 1):\n",
      "        # Multiply the result by i\n",
      "        result *= i\n",
      "    \n",
      "    return result\n",
      "\n",
      "# Test the function with a sample input\n",
      "num = int(input(\"Enter a number: \"))\n",
      "print(f\"The factorial of {num} is {factorial(num)}\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import sys\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PROMPT TEMPLATE FUNCTION (C++ version)\n",
    "# ==============================================================================\n",
    "def create_description_template():\n",
    "    \"\"\"\n",
    "    Creates a PromptTemplate configured for a Python code generation LLM.\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "You are an expert Python programmer. The user will provide you with a question or request.\n",
    "Your task is to write a perfect, optimized, yet simplified Python code solution for the user's request.\n",
    "\n",
    "**Instructions:**\n",
    "- Include comments in the generated code to explain key parts.\n",
    "- Describe the thinking process briefly in a single comment block.\n",
    "- Write short, simple, and optimized Python code that directly solves the user's request.\n",
    "- Output only a valid JSON array. Do NOT wrap the code in triple quotes.\n",
    "- Escape all internal double quotes in the code.\n",
    "- The JSON array must contain exactly one object with the keys \"question\" and \"code\".\n",
    "\n",
    "**Input question:**\n",
    "{user_request}\n",
    "\n",
    "**Output format** (MUST be a JSON array with one object):\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"The user's original input question here...\",\n",
    "        \"code\": \"The full, optimized, and simplified Python code with comments here...\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "Return only the JSON array as output.\n",
    "Begin.\n",
    "\"\"\"\n",
    "    return PromptTemplate(input_variables=[\"user_request\"], template=template)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ROBUST JSON EXTRACTION FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_json_from_llm_output(output_str: str) -> list:\n",
    "    \"\"\"\n",
    "    Robustly extracts a JSON array from the LLM output, fixing common\n",
    "    issues like triple-quoted code fields and unescaped double quotes\n",
    "    and newlines within the code block.\n",
    "    Returns a Python list.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import json\n",
    "\n",
    "    output_str = output_str.strip()\n",
    "\n",
    "    # 1. Look for the JSON array structure [ ... ]\n",
    "    match = re.search(r'\\[\\s*\\{[\\s\\S]*?\\}\\s*\\]', output_str, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No JSON array structure found in LLM output.\")\n",
    "\n",
    "    json_str = match.group(0)\n",
    "\n",
    "    # 2. Find each \"code\": occurrence and replace its raw content with a safely escaped JSON string\n",
    "    last_end = 0\n",
    "    parts = []\n",
    "    for m in re.finditer(r'\"code\"\\s*:', json_str):\n",
    "        # if this found \"code\": is inside a region we've already processed, skip it\n",
    "        if m.start() < last_end:\n",
    "            continue\n",
    "\n",
    "        # append text before this \"code\":\n",
    "        parts.append(json_str[last_end:m.start()])\n",
    "\n",
    "        # advance pointer to char after the colon\n",
    "        j = m.end()\n",
    "        # skip whitespace\n",
    "        while j < len(json_str) and json_str[j].isspace():\n",
    "            j += 1\n",
    "\n",
    "        # detect delimiter: triple quotes or single double-quote\n",
    "        if json_str.startswith('\"\"\"', j) or json_str.startswith(\"'''\", j):\n",
    "            delim = json_str[j:j+3]\n",
    "            content_start = j + 3\n",
    "            end_idx = json_str.find(delim, content_start)\n",
    "            if end_idx == -1:\n",
    "                raise ValueError(\"Unterminated triple-quoted code block in LLM output.\")\n",
    "            raw_code = json_str[content_start:end_idx]\n",
    "            after_end = end_idx + 3\n",
    "        elif j < len(json_str) and json_str[j] == '\"':\n",
    "            # normal double-quoted string — find the closing unescaped quote\n",
    "            content_start = j + 1\n",
    "            k = content_start\n",
    "            while k < len(json_str):\n",
    "                if json_str[k] == '\"' and json_str[k-1] != '\\\\':\n",
    "                    break\n",
    "                k += 1\n",
    "            if k >= len(json_str):\n",
    "                raise ValueError(\"Unterminated quoted string for code field.\")\n",
    "            raw_code = json_str[content_start:k]\n",
    "            after_end = k + 1\n",
    "        else:\n",
    "            # Unexpected format (for example code left unquoted). Try to recover:\n",
    "            # capture until the next closing brace of the object or until next \"key\":\n",
    "            # this is a best-effort fallback.\n",
    "            fallback_match = re.search(r'(?:\\n\\s*\\}\\s*|\\n\\s*\"[A-Za-z0-9_]+\\s*\"\\s*:)', json_str[j:], re.DOTALL)\n",
    "            if fallback_match:\n",
    "                raw_code = json_str[j:j + fallback_match.start()]\n",
    "                after_end = j + fallback_match.start()\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected format for code field in LLM output.\")\n",
    "\n",
    "        # --- sanitize/escape the raw code content for JSON ---\n",
    "        code_content = raw_code\n",
    "        code_content = code_content.replace('\\\\', '\\\\\\\\')   # escape backslashes first\n",
    "        code_content = code_content.replace('\"', '\\\\\"')     # escape double quotes\n",
    "        code_content = code_content.replace('\\n', '\\\\n').replace('\\r', '')  # escape newlines\n",
    "\n",
    "        # insert the safe JSON key:value for code\n",
    "        parts.append(f'\"code\":\"{code_content}\"')\n",
    "\n",
    "        # set last_end to continue after the original code block\n",
    "        last_end = after_end\n",
    "\n",
    "    # append the remainder of the JSON string\n",
    "    parts.append(json_str[last_end:])\n",
    "    fixed_json_str = ''.join(parts)\n",
    "\n",
    "    # 3. Parse JSON\n",
    "    try:\n",
    "        data = json.loads(fixed_json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to parse JSON: {e}\\nSanitized JSON:\\n{fixed_json_str}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LLM INITIALIZATION\n",
    "# ==============================================================================\n",
    "def get_mock_llm_fallback():\n",
    "    \"\"\"Returns a mock LLM object as a fallback.\"\"\"\n",
    "    class MockLLM:\n",
    "        def invoke(self, input_vars):\n",
    "            user_request = input_vars['user_request']\n",
    "            return f\"\"\"\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"{user_request}\",\n",
    "        \"code\": \"// Mock LLM: Please start Ollama and load 'llama3'.\\\\n#include <iostream>\\\\nint main() {{ std::cout << 'Mock output!'; return 0; }}\"\n",
    "    }}\n",
    "]\n",
    "\"\"\"\n",
    "    return MockLLM()\n",
    "\n",
    "def initialize_llm_with_ollama(model_name: str = \"llama3\"):\n",
    "    print(f\"Attempting to initialize Ollama with model: {model_name}...\")\n",
    "    try:\n",
    "        llm = OllamaLLM(model=model_name, temperature=0.1)\n",
    "        llm.invoke(\"Test\")  # Test connectivity\n",
    "        print(\"Ollama connection successful.\\n\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ollama connection issue: {e}\", file=sys.stderr)\n",
    "        print(\"Falling back to Mock LLM.\\n\", file=sys.stderr)\n",
    "        return get_mock_llm_fallback()\n",
    "\n",
    "# Initialize LLM\n",
    "llm_desc = initialize_llm_with_ollama(\"llama3\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MAIN EXECUTION LOGIC\n",
    "# ==============================================================================\n",
    "def run_code_generator():\n",
    "    user_request = input(\"Enter your Python problem (e.g., Write a Python program to calculate the factorial of a given number using a loop.): \")\n",
    "    prompt_vars = {'user_request': user_request}\n",
    "\n",
    "    # Modern LCEL chain: prompt | llm\n",
    "    desc_prompt = create_description_template()\n",
    "    chain = desc_prompt | llm_desc\n",
    "\n",
    "    print(\"\\n--- Invoking LLM Chain ---\")\n",
    "    response_text = chain.invoke(prompt_vars)\n",
    "    print(response_text)\n",
    "\n",
    "    # Extraction & parsing\n",
    "    try:\n",
    "        data = extract_json_from_llm_output(response_text)  # Python list\n",
    "        print(data)\n",
    "        result = data[0]\n",
    "        print(result)\n",
    "        extracted_question = result.get('question', 'N/A')\n",
    "        print(extracted_question)\n",
    "        generated_code = result.get('code', 'Error: Code not found')\n",
    "        print(generated_code)\n",
    "\n",
    "        print(\"\\n--- Extracted Results ---\")\n",
    "        print(f\"Original Question: {extracted_question}\\n\")\n",
    "        print(f\"Generated Python Code:\\n{generated_code}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- ERROR ---\", file=sys.stderr)\n",
    "        print(f\"Could not parse or extract data: {e}\", file=sys.stderr)\n",
    "        print(f\"Raw output received:\\n{response_text}\", file=sys.stderr)\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. ENTRY POINT\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_code_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2046ba5-91ed-4797-8c35-ab37575f23d2",
   "metadata": {},
   "source": [
    "# Chatbot Code C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca82803-10eb-48f7-a417-2c397a85526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to initialize Ollama with model: llama3...\n",
      "Ollama connection successful.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your C++ problem (e.g., Write a C++ function to find the largest number in an integer array.):  Write a program to add 2 digits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Invoking LLM Chain ---\n",
      "[\n",
      "    {\n",
      "        \"question\": \"Write a program to add 2 digits.\",\n",
      "        \"code\": \"\"\"\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "    int num1, num2, sum;\n",
      "\n",
      "    // Ask for two numbers\n",
      "    std::cout << \"Enter the first number: \";\n",
      "    std::cin >> num1;\n",
      "    std::cout << \"Enter the second number: \";\n",
      "    std::cin >> num2;\n",
      "\n",
      "    // Add the numbers\n",
      "    sum = num1 + num2;\n",
      "\n",
      "    // Print the result\n",
      "    std::cout << \"The sum is: \" << sum << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\"\"\"\n",
      "    }\n",
      "]\n",
      "[{'question': 'Write a program to add 2 digits.', 'code': '\\n#include <iostream>\\n\\nint main() {\\n    int num1, num2, sum;\\n\\n    // Ask for two numbers\\n    std::cout << \"Enter the first number: \";\\n    std::cin >> num1;\\n    std::cout << \"Enter the second number: \";\\n    std::cin >> num2;\\n\\n    // Add the numbers\\n    sum = num1 + num2;\\n\\n    // Print the result\\n    std::cout << \"The sum is: \" << sum << std::endl;\\n\\n    return 0;\\n}\\n'}]\n",
      "{'question': 'Write a program to add 2 digits.', 'code': '\\n#include <iostream>\\n\\nint main() {\\n    int num1, num2, sum;\\n\\n    // Ask for two numbers\\n    std::cout << \"Enter the first number: \";\\n    std::cin >> num1;\\n    std::cout << \"Enter the second number: \";\\n    std::cin >> num2;\\n\\n    // Add the numbers\\n    sum = num1 + num2;\\n\\n    // Print the result\\n    std::cout << \"The sum is: \" << sum << std::endl;\\n\\n    return 0;\\n}\\n'}\n",
      "Write a program to add 2 digits.\n",
      "\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "    int num1, num2, sum;\n",
      "\n",
      "    // Ask for two numbers\n",
      "    std::cout << \"Enter the first number: \";\n",
      "    std::cin >> num1;\n",
      "    std::cout << \"Enter the second number: \";\n",
      "    std::cin >> num2;\n",
      "\n",
      "    // Add the numbers\n",
      "    sum = num1 + num2;\n",
      "\n",
      "    // Print the result\n",
      "    std::cout << \"The sum is: \" << sum << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "\n",
      "--- Extracted Results ---\n",
      "Original Question: Write a program to add 2 digits.\n",
      "\n",
      "Generated C++ Code:\n",
      "\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "    int num1, num2, sum;\n",
      "\n",
      "    // Ask for two numbers\n",
      "    std::cout << \"Enter the first number: \";\n",
      "    std::cin >> num1;\n",
      "    std::cout << \"Enter the second number: \";\n",
      "    std::cin >> num2;\n",
      "\n",
      "    // Add the numbers\n",
      "    sum = num1 + num2;\n",
      "\n",
      "    // Print the result\n",
      "    std::cout << \"The sum is: \" << sum << std::endl;\n",
      "\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import sys\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PROMPT TEMPLATE FUNCTION (C++ version)\n",
    "# ==============================================================================\n",
    "def create_description_template():\n",
    "    \"\"\"\n",
    "    Creates a PromptTemplate configured for a C++ code generation LLM.\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "You are an expert C++ programmer. The user will provide you with a question or request.\n",
    "Your task is to write a perfect, optimized, yet simplified C++ code solution for the user's request.\n",
    "\n",
    "**Instructions:**\n",
    "- Include comments in the generated code to explain key parts.\n",
    "- Describe the thinking process briefly in a single comment block.\n",
    "- Write short, simple, and optimized C++ code that directly solves the user's request.\n",
    "- Output only a valid JSON array. Do NOT wrap the code in triple quotes.\n",
    "- Escape all internal double quotes in the code.\n",
    "- The JSON array must contain exactly one object with the keys \"question\" and \"code\".\n",
    "\n",
    "**Input question:**\n",
    "{user_request}\n",
    "\n",
    "**Output format** (MUST be a JSON array with one object):\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"The user's original input question here...\",\n",
    "        \"code\": \"The full, optimized, and simplified C++ code with comments here...\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "Return only the JSON array as output.\n",
    "Begin.\n",
    "\"\"\"\n",
    "    return PromptTemplate(input_variables=[\"user_request\"], template=template)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ROBUST JSON EXTRACTION FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_json_from_llm_output(output_str: str) -> list:\n",
    "    \"\"\"\n",
    "    Robustly extracts a JSON array from the LLM output, fixing common\n",
    "    issues like triple-quoted code fields and unescaped double quotes\n",
    "    and newlines within the code block.\n",
    "    Returns a Python list.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import json\n",
    "\n",
    "    output_str = output_str.strip()\n",
    "\n",
    "    # 1. Look for the JSON array structure [ ... ]\n",
    "    match = re.search(r'\\[\\s*\\{[\\s\\S]*?\\}\\s*\\]', output_str, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No JSON array structure found in LLM output.\")\n",
    "\n",
    "    json_str = match.group(0)\n",
    "\n",
    "    # 2. Find each \"code\": occurrence and replace its raw content with a safely escaped JSON string\n",
    "    last_end = 0\n",
    "    parts = []\n",
    "    for m in re.finditer(r'\"code\"\\s*:', json_str):\n",
    "        # if this found \"code\": is inside a region we've already processed, skip it\n",
    "        if m.start() < last_end:\n",
    "            continue\n",
    "\n",
    "        # append text before this \"code\":\n",
    "        parts.append(json_str[last_end:m.start()])\n",
    "\n",
    "        # advance pointer to char after the colon\n",
    "        j = m.end()\n",
    "        # skip whitespace\n",
    "        while j < len(json_str) and json_str[j].isspace():\n",
    "            j += 1\n",
    "\n",
    "        # detect delimiter: triple quotes or single double-quote\n",
    "        if json_str.startswith('\"\"\"', j) or json_str.startswith(\"'''\", j):\n",
    "            delim = json_str[j:j+3]\n",
    "            content_start = j + 3\n",
    "            end_idx = json_str.find(delim, content_start)\n",
    "            if end_idx == -1:\n",
    "                raise ValueError(\"Unterminated triple-quoted code block in LLM output.\")\n",
    "            raw_code = json_str[content_start:end_idx]\n",
    "            after_end = end_idx + 3\n",
    "        elif j < len(json_str) and json_str[j] == '\"':\n",
    "            # normal double-quoted string — find the closing unescaped quote\n",
    "            content_start = j + 1\n",
    "            k = content_start\n",
    "            while k < len(json_str):\n",
    "                if json_str[k] == '\"' and json_str[k-1] != '\\\\':\n",
    "                    break\n",
    "                k += 1\n",
    "            if k >= len(json_str):\n",
    "                raise ValueError(\"Unterminated quoted string for code field.\")\n",
    "            raw_code = json_str[content_start:k]\n",
    "            after_end = k + 1\n",
    "        else:\n",
    "            # Unexpected format (for example code left unquoted). Try to recover:\n",
    "            # capture until the next closing brace of the object or until next \"key\":\n",
    "            # this is a best-effort fallback.\n",
    "            fallback_match = re.search(r'(?:\\n\\s*\\}\\s*|\\n\\s*\"[A-Za-z0-9_]+\\s*\"\\s*:)', json_str[j:], re.DOTALL)\n",
    "            if fallback_match:\n",
    "                raw_code = json_str[j:j + fallback_match.start()]\n",
    "                after_end = j + fallback_match.start()\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected format for code field in LLM output.\")\n",
    "\n",
    "        # --- sanitize/escape the raw code content for JSON ---\n",
    "        code_content = raw_code\n",
    "        code_content = code_content.replace('\\\\', '\\\\\\\\')   # escape backslashes first\n",
    "        code_content = code_content.replace('\"', '\\\\\"')     # escape double quotes\n",
    "        code_content = code_content.replace('\\n', '\\\\n').replace('\\r', '')  # escape newlines\n",
    "\n",
    "        # insert the safe JSON key:value for code\n",
    "        parts.append(f'\"code\":\"{code_content}\"')\n",
    "\n",
    "        # set last_end to continue after the original code block\n",
    "        last_end = after_end\n",
    "\n",
    "    # append the remainder of the JSON string\n",
    "    parts.append(json_str[last_end:])\n",
    "    fixed_json_str = ''.join(parts)\n",
    "\n",
    "    # 3. Parse JSON\n",
    "    try:\n",
    "        data = json.loads(fixed_json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Failed to parse JSON: {e}\\nSanitized JSON:\\n{fixed_json_str}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LLM INITIALIZATION\n",
    "# ==============================================================================\n",
    "def get_mock_llm_fallback():\n",
    "    \"\"\"Returns a mock LLM object as a fallback.\"\"\"\n",
    "    class MockLLM:\n",
    "        def invoke(self, input_vars):\n",
    "            user_request = input_vars['user_request']\n",
    "            return f\"\"\"\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"{user_request}\",\n",
    "        \"code\": \"// Mock LLM: Please start Ollama and load 'llama3'.\\\\n#include <iostream>\\\\nint main() {{ std::cout << 'Mock output!'; return 0; }}\"\n",
    "    }}\n",
    "]\n",
    "\"\"\"\n",
    "    return MockLLM()\n",
    "\n",
    "def initialize_llm_with_ollama(model_name: str = \"llama3\"):\n",
    "    print(f\"Attempting to initialize Ollama with model: {model_name}...\")\n",
    "    try:\n",
    "        llm = OllamaLLM(model=model_name, temperature=0.1)\n",
    "        llm.invoke(\"Test\")  # Test connectivity\n",
    "        print(\"Ollama connection successful.\\n\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ollama connection issue: {e}\", file=sys.stderr)\n",
    "        print(\"Falling back to Mock LLM.\\n\", file=sys.stderr)\n",
    "        return get_mock_llm_fallback()\n",
    "\n",
    "# Initialize LLM\n",
    "llm_desc = initialize_llm_with_ollama(\"llama3\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MAIN EXECUTION LOGIC\n",
    "# ==============================================================================\n",
    "def run_code_generator():\n",
    "    user_request = input(\"Enter your C++ problem (e.g., Write a C++ function to find the largest number in an integer array.): \")\n",
    "    prompt_vars = {'user_request': user_request}\n",
    "\n",
    "    # Modern LCEL chain: prompt | llm\n",
    "    desc_prompt = create_description_template()\n",
    "    chain = desc_prompt | llm_desc\n",
    "\n",
    "    print(\"\\n--- Invoking LLM Chain ---\")\n",
    "    response_text = chain.invoke(prompt_vars)\n",
    "    print(response_text)\n",
    "\n",
    "    # Extraction & parsing\n",
    "    try:\n",
    "        data = extract_json_from_llm_output(response_text)  # Python list\n",
    "        print(data)\n",
    "        result = data[0]\n",
    "        print(result)\n",
    "        extracted_question = result.get('question', 'N/A')\n",
    "        print(extracted_question)\n",
    "        generated_code = result.get('code', 'Error: Code not found')\n",
    "        print(generated_code)\n",
    "\n",
    "        print(\"\\n--- Extracted Results ---\")\n",
    "        print(f\"Original Question: {extracted_question}\\n\")\n",
    "        print(f\"Generated C++ Code:\\n{generated_code}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- ERROR ---\", file=sys.stderr)\n",
    "        print(f\"Could not parse or extract data: {e}\", file=sys.stderr)\n",
    "        print(f\"Raw output received:\\n{response_text}\", file=sys.stderr)\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. ENTRY POINT\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_code_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253a0ea-9d78-496d-aa29-54ea9ecd492d",
   "metadata": {},
   "source": [
    "# Test the code given by the bot in the below cell-> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d08adf-ec5f-48de-a75f-fa0b696d1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Python function that takes a list of names and returns a dictionary \n",
    "#where keys are the first letters and values are lists of names starting with that letter\n",
    "\n",
    "def group_names_by_first_letter(names):\n",
    "    # Initialize an empty dictionary to store the result\n",
    "    result = {}\n",
    "    \n",
    "    # Iterate over each name in the input list\n",
    "    for name in names:\n",
    "        # Get the first letter of the current name\n",
    "        first_letter = name[0].upper()\n",
    "        \n",
    "        # If the first letter is not already a key in the result dictionary, add it with an empty list as its value\n",
    "        if first_letter not in result:\n",
    "            result[first_letter] = []\n",
    "        \n",
    "        # Add the current name to the list of names starting with the same first letter\n",
    "        result[first_letter].append(name)\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
